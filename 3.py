# -*- coding: utf-8 -*-
"""ami_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I6MTUGZ8Dz6O7VXBnvczalfvuT18yqqs

You can use this template for problems 1, 2 and 3
"""

import numpy as np
import time
# Students will submit their files with their team-name.py
# Student have to use the Team as their parent class

"""Recent Version of the Code"""

class Agent:
  def __init__(self):
    self.N= np.zeros(6)
    self.S =np.zeros(6)
    self.W= np.zeros(6)
    self.VW = np.zeros(6)
    self.VS = np.zeros(6)
    self.prev = -1
    self.t = 0
    self.ucb =np.ones(6)*np.inf
    self.alpha = 1


  def get_action(self, wicket, runs_scored):
    if self.prev != -1:
      self.N[self.prev] += 1
      self.t += 1
      self.S[self.prev] += runs_scored
      self.VS[self.prev] += (runs_scored-self.S[self.prev]/self.N[self.prev])** 2
      self.W[self.prev] += wicket
      self.VW[self.prev] += (wicket-self.W[self.prev]/self.N[self.prev])** 2

      r = self.S[self.prev] / max(self.W[self.prev],1e-8)
      eps = np.sqrt(2*self.VS[self.prev]*np.log(self.t**self.alpha)/(self.N[self.prev] **2))+18*np.log(self.t**self.alpha) /self.N[self.prev]
      eta = np.sqrt(2*self.VW[self.prev]*np.log(self.t**self.alpha)/(self.N[self.prev] **2))+3*np.log(self.t**self.alpha) /self.N[self.prev]
      c = 1.4*(eps + r*eta) / max(self.W[self.prev]/self.N[self.prev],1e-8)
      self.ucb[self.prev] = r+c

    self.prev = np.argmax(self.ucb)
    return self.prev

class Environment:
  def __init__(self,num_balls,agent):
    self.num_balls = num_balls
    self.agent = agent
    self.__run_time = 0
    self.__total_runs = 0
    self.__total_wickets = 0
    self.__runs_scored = 0
    self.__start_time = 0
    self.__end_time = 0
    self.__regret_w = 0
    self.__regret_s = 0
    self.__wicket = 0
    self.__regret_rho = 0
    self.__p_out = np.array([0.001,0.01,0.02,0.03,0.1,0.3])
    self.__p_run = np.array([1,0.9,0.85,0.8,0.75,0.7])
    self.__action_runs_map = np.array([0,1,2,3,4,6])
    self.__s = (1-self.__p_out)*self.__p_run*self.__action_runs_map
    self.__rho = self.__s/self.__p_out


  def __get_action(self):
    self.__start_time      = time. time()
    action          = self.agent.get_action(self.__wicket,self.__runs_scored)
    self.__end_time        = time. time()
    self.__run_time   = self.__run_time + self.__end_time - self.__start_time
    return action


  def __get_outcome(self, action):
    pout = self.__p_out[action]
    prun= self.__p_run[action]
    wicket = np.random.choice(2,1,p=[1-pout,pout])[0]
    runs = 0
    if(wicket==0):
      runs = self.__action_runs_map[action]*np.random.choice(2,1,p=[1-prun,prun])[0]
    return wicket, runs


  def innings(self):
    self.__total_runs = 0
    self.__total_wickets = 0
    self.__runs_scored = 0

    for ball in range(self.num_balls):
      action = self.__get_action()
      self.__wicket, self.__runs_scored   = self.__get_outcome(action)
      self.__total_runs     = self.__total_runs + self.__runs_scored
      self.__total_wickets  = self.__total_wickets + self.__wicket
      self.__regret_w       = self.__regret_w+ (self.__p_out[action]-np.min(self.__p_out))
      self.__regret_s       = self.__regret_s+ (np.max(self.__s) - self.__s[action])
      self.__regret_rho       = self.__regret_rho+ (np.max(self.__rho)-self.__rho[action])
    return self.__regret_w,self.__regret_s,self.__regret_rho, self.__total_runs, self.__total_wickets, self.__run_time

agent = Agent()
environment = Environment(100,agent)
regret_w,regret_s,reger_rho,total_runs,total_wickets,run_time = environment.innings()

print(regret_w,regret_s,reger_rho,total_runs,total_wickets,run_time)

balles = [10,100,1000,10000,100000]
regrer = []
regres = []
regrew = []
for balle in balles:
  agent = Agent()
  environment = Environment(balle,agent)
  regret_w,regret_s,reger_rho,total_runs,total_wickets,run_time = environment.innings()
  regrer.append(reger_rho)
  regres.append(regret_s)
  regrew.append(regret_w)

print(regrew)

print(regres)

print(regrer)

arr_s = np.zeros(1000)
arr_w = np.zeros(1000)
arr_r = np.zeros(1000)
for num in range(1000):
  agent = Agent()
  environment = Environment(100,agent)
  regret_w,regret_s,reger_rho,total_runs,total_wickets,run_time = environment.innings()
  arr_s[num] = regret_s
  arr_w[num] = regret_w
  arr_r[num] = reger_rho

print(np.amin(arr_w),np.amax(arr_w),np.std(arr_w),np.mean(arr_w))

print(np.amin(arr_s),np.amax(arr_s),np.std(arr_s),np.mean(arr_s))

print(np.amin(arr_r),np.amax(arr_r),np.std(arr_r),np.mean(arr_r))

